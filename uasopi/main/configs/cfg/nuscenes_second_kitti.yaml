
name: NuScenes
dataset_name: NuScenes
dataset_root: /home/mmc-server4/Server/Datasets_hdd/nuscenes
desc: inI_predI
save_dir: /home/mmc-server4/Server/Users/hayeon/uasopi/main/result/nuscenes

# splits
train_split: parametrizing
val_split: verifying
test_split: val

# inputs
inputs: ["pos", "intensities"] 

# optimization
training:
  max_epochs: 100
  batch_size: 4
  val_interval: 5

optimizer: torch.optim.AdamW
optimizer_params:
  lr: 0.001

# network
network:
  framework: spconv
  backbone: SECOND
  backbone_params: 
    config: "./configs/misc/second_for_pretraining_kitti.yaml"
    quantization_params:
      spatial_extent: [0, -40, -5, 70.4, 40, 3] # spatial extent of the scene (only for spconv)
      voxel_size: [0.05, 0.05, 0.1]
    dropout :
      usage : true
      rate: 0.2
  decoder: InterpNet
  decoder_params:
    radius: 1.0
    column_search: true
    out_channels: 2
    intensity_loss: true
    uncertainty_loss: true
    radius_search: true
    dropout :
      usage : true
      rate: 0.2
  latent_size: 128


# losses
loss:
  recons_loss_lambda: 1
  intensity_loss_lambda: 1
  uncertainty_loss_lambda : 0.01

# misc
device: cuda
num_device: 1
threads: 14
interactive_log: false
logging: INFO
resume: null

# sampling
manifold_points: 80000
non_manifold_points: 4096

# data augmentation
transforms:
  voxel_decimation: 0.05
  scaling_intensities: false
  random_rotation_z: true
  random_flip: true

uncertainty_quantification: true
monte-carlo_method:
  mc_samples: 30 
  drop_rate : 0.2
  adf : True

# wandb
wandb:
  usage : True
  project: "UASOPI"
  entity: "ophd"
  # save_dir: "wandb/"
  name: "nuscenes_spconv_SECOND_one_dropout_0.2_tail_of_backbone3d_decoder_demo_adf"